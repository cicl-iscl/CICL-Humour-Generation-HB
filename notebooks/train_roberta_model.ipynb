{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c87bed-67da-4b98-8338-4f526446d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate>=0.26.0\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.3.9)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.6.0+cu124)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.13.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m267.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m142.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m261.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m175.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m252.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m153.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Installing collected packages: xxhash, sentencepiece, safetensors, regex, pyarrow, propcache, multidict, hf-xet, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, accelerate, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed accelerate-1.11.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 datasets-4.4.1 dill-0.4.0 frozenlist-1.8.0 hf-xet-1.2.0 huggingface-hub-0.36.0 multidict-6.7.0 multiprocess-0.70.18 propcache-0.4.1 pyarrow-22.0.0 regex-2025.11.3 safetensors-0.6.2 sentencepiece-0.2.1 tokenizers-0.22.1 transformers-4.57.1 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets 'accelerate>=0.26.0' sentencepiece -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e3d784-b853-4b36-8975-4a9a48285cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# eval_df = pd.read_csv(\"eval_data.csv\")\n",
    "eval_df = pd.read_csv(\"data_llm_eval.csv\")\n",
    "eval_df = eval_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167579a4-5d3e-49c8-8f3c-c3707cfa9bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>joke</th>\n",
       "      <th>score</th>\n",
       "      <th>llama_score</th>\n",
       "      <th>llama_reason</th>\n",
       "      <th>gpt_score</th>\n",
       "      <th>gpt_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What do you call a mushroom that buys all the ...</td>\n",
       "      <td>0.427833</td>\n",
       "      <td>7</td>\n",
       "      <td>The joke is a play on words, using the scienti...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The joke relies on a classic pun (fungi/fun‑gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What did the digital clock say to the grandfat...</td>\n",
       "      <td>0.376117</td>\n",
       "      <td>8</td>\n",
       "      <td>The joke is a play on words, using the phrase ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The joke is a simple pun about a digital clock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm in the terminator musical. I'll be Bach.</td>\n",
       "      <td>0.314998</td>\n",
       "      <td>8</td>\n",
       "      <td>This joke is a play on words, combining the co...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The joke is a short pun that mixes the Termina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Will you tell you the story of the huge sad wa...</td>\n",
       "      <td>0.404325</td>\n",
       "      <td>8</td>\n",
       "      <td>This joke is a play on words, using the phrase...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The joke relies on a simple pun—'you'll never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What do you call a cat in an iron man suit ? I...</td>\n",
       "      <td>0.319699</td>\n",
       "      <td>6</td>\n",
       "      <td>The joke is a play on words, combining 'Iron M...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The joke is a straightforward pun (Iron Meow) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               joke     score  \\\n",
       "0   1  What do you call a mushroom that buys all the ...  0.427833   \n",
       "1   2  What did the digital clock say to the grandfat...  0.376117   \n",
       "2   3       I'm in the terminator musical. I'll be Bach.  0.314998   \n",
       "3   4  Will you tell you the story of the huge sad wa...  0.404325   \n",
       "4   5  What do you call a cat in an iron man suit ? I...  0.319699   \n",
       "\n",
       "   llama_score                                       llama_reason  gpt_score  \\\n",
       "0            7  The joke is a play on words, using the scienti...        5.0   \n",
       "1            8  The joke is a play on words, using the phrase ...        5.0   \n",
       "2            8  This joke is a play on words, combining the co...        6.0   \n",
       "3            8  This joke is a play on words, using the phrase...        5.0   \n",
       "4            6  The joke is a play on words, combining 'Iron M...        5.0   \n",
       "\n",
       "                                          gpt_reason  \n",
       "0  The joke relies on a classic pun (fungi/fun‑gu...  \n",
       "1  The joke is a simple pun about a digital clock...  \n",
       "2  The joke is a short pun that mixes the Termina...  \n",
       "3  The joke relies on a simple pun—'you'll never ...  \n",
       "4  The joke is a straightforward pun (Iron Meow) ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aee3b7a-6084-424c-9bb0-f32df3361426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "eval_df[\"labels\"] = (eval_df[\"llama_score\"] + eval_df[\"gpt_score\"]) // 2\n",
    "eval_df[\"labels\"] = eval_df[\"labels\"] = eval_df[\"labels\"].replace(-1, 0)\n",
    "eval_df.labels = eval_df.labels.astype(int)\n",
    "eval_df.joke = eval_df.joke.astype(str)\n",
    "eval_df = eval_df[[\"joke\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f0c82e-8dfc-4377-ae2a-7127e1433aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df = pd.read_csv(\"eval_data.csv\")\n",
    "synthetic_df[\"labels\"] = synthetic_df.score\n",
    "synthetic_df = synthetic_df[[\"joke\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d33aeed5-82cf-4af5-9251-6abe11eb28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.concat([eval_df, synthetic_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25b28ff-a8d8-444d-9bfa-ead7b57802de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What do you call a mushroom that buys all the ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What did the digital clock say to the grandfat...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm in the terminator musical. I'll be Bach.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will you tell you the story of the huge sad wa...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do you call a cat in an iron man suit ? I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                joke  labels\n",
       "0  What do you call a mushroom that buys all the ...       6\n",
       "1  What did the digital clock say to the grandfat...       6\n",
       "2       I'm in the terminator musical. I'll be Bach.       7\n",
       "3  Will you tell you the story of the huge sad wa...       6\n",
       "4  What do you call a cat in an iron man suit ? I...       5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a876ca7e-09a4-435f-9d75-e9cb4e70ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42083\n",
      "5260\n",
      "5261\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(eval_df, test_size=0.2, random_state=42, stratify=eval_df.labels)\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42, stratify=test_df.labels)\n",
    "print(len(train_df))\n",
    "print(len(test_df))\n",
    "print(len(val_df))\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "val_ds = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba6ea78f-3bad-405c-97b0-cb406439a54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f320a376ae4469a6a7e9a3883b3f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3679d9cc6d124db6ac089de5bb23c021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90584100551246099b5ca442baa1cf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a97318360d247749eca3c1e58622e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a455d7f445b467c86873b8d8fdf19d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42083 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e35a69b438245ba92798aa04040bcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d011d797b44ee3a6619058fcce02cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"FacebookAI/xlm-roberta-large\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"joke\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "test_ds = test_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae95ccca-adde-4ce4-b9fc-919e5894f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    rmse = mean_squared_error(labels, preds)\n",
    "    mae = mean_absolute_error(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"rmse\": rmse, \"accuracy\": acc, \"mae\": mae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df31d32f-a683-4310-acb7-390334f4a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train_ds[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c1bf3d-fe50-496e-952b-5f70f94d29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "binary_counts = np.array([(labels == 0).sum(), (labels != 0).sum()], dtype=float)\n",
    "\n",
    "binary_weights = (binary_counts.sum() / (2 * binary_counts))\n",
    "binary_weights = torch.tensor(binary_weights, dtype=torch.float)\n",
    "\n",
    "child_labels = labels[labels != 0]    # keep only 1–10\n",
    "child_counts = np.array([(child_labels == c).sum() for c in range(1, train_df.labels.nunique())], dtype=float)\n",
    "\n",
    "child_weights = (child_counts.sum() / (10 * child_counts))\n",
    "child_weights = torch.tensor(child_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8daa21-5f75-4d52-81f2-62353e50adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaPreTrainedModel, XLMRobertaModel\n",
    "\n",
    "class HierarchicalClassifier(XLMRobertaPreTrainedModel):\n",
    "    \n",
    "    def __init__(self, config, num_child_labels=10, class_weights_binary=None, class_weights_child=None):\n",
    "        h = config.hidden_size\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.roberta = XLMRobertaModel(config)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.proj = nn.Linear(h, h//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.binary_head = nn.Linear(h//2, 2)\n",
    "        self.child_head = nn.Linear(h//2, num_child_labels)\n",
    "        self.loss_bin = nn.CrossEntropyLoss(weight=class_weights_binary)\n",
    "        self.loss_child = nn.CrossEntropyLoss(weight=class_weights_child)\n",
    "        \n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        a = torch.tensor(0.5, requires_grad=True)\n",
    "        b = torch.tensor(0.5, requires_grad=True)\n",
    "        loss = None\n",
    "        \n",
    "        x = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        x = x.last_hidden_state[:, 0] # cls token\n",
    "        x = self.dropout(x)\n",
    "        x = self.proj(x)\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        lb = self.binary_head(x)\n",
    "        lc = self.child_head(x)\n",
    "\n",
    "        pb = torch.softmax(lb, dim=-1)\n",
    "        pc = torch.softmax(lc, dim=-1)\n",
    "        sc = pc * pb[:, 1].unsqueeze(-1)\n",
    "        logits = torch.cat([pb[:, 0].unsqueeze(-1), sc], dim=-1)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        expected = (probs * torch.arange(0, logits.size(1), device=logits.device)).sum(dim=-1)\n",
    "        reg_loss = torch.mean((expected - labels.float()) ** 2)\n",
    "        \n",
    "        if labels is not None:\n",
    "            bt = (labels != 0).long()\n",
    "            loss_b = self.loss_bin(lb, bt)\n",
    "            nz = bt == 1\n",
    "            if nz.any():\n",
    "                cl = labels[nz] - 1\n",
    "                loss_c = self.loss_child(lc[nz], cl)\n",
    "            else:\n",
    "                loss_c = 0.0\n",
    "            clf_loss = loss_b + loss_c\n",
    "\n",
    "            loss = a * reg_loss + b * clf_loss\n",
    "        \n",
    "        return {\"loss\": loss, \"logits\": logits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ec1d8c-5ae0-4a71-8c3d-16e6b5e4c298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245aa376fac0470aa9ff53817924ab89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HierarchicalClassifier were not initialized from the model checkpoint at FacebookAI/xlm-roberta-large and are newly initialized: ['binary_head.bias', 'binary_head.weight', 'child_head.bias', 'child_head.weight', 'loss_bin.weight', 'loss_child.weight', 'proj.bias', 'proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "n_labels = len(train_df.labels.unique())\n",
    "# model = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=n_labels)\n",
    "\n",
    "model = HierarchicalClassifier.from_pretrained(\n",
    "    model_name,\n",
    "    num_child_labels=n_labels-1,\n",
    "    class_weights_binary=binary_weights,\n",
    "    class_weights_child=child_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "865ee548-d200-49bf-96cc-68c15373b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./xlm-roberta-joke-rating\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=2e-5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cff43-7f3e-4429-af95-45ee38feb6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='979' max='78930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  979/78930 02:06 < 2:48:05, 7.73 it/s, Epoch 0.37/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd92d9-9700-4f16-9315-d13d8ce66f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd964ef-b3c8-4cd4-ad8b-3c2f9d9043fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
